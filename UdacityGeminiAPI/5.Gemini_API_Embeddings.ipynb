{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This notebook uses Gemini 1.5 Flash and covers the generation of embeddings for different types of data through the Gemini api\n",
        "\n",
        "###Embedding: a list of decimal point numbers that represent the meaning of aword/sentence/paragraph. A quantity of these numbers represent *dimensionality* of embeddings.\n",
        "\n",
        "###Embeddings can be used in document search, anomaly detection, text classification, and many other tasks!\n",
        "\n",
        "### **It can greatly enhance text processing and retrival capabilities**"
      ],
      "metadata": {
        "id": "xBU-dactYcJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "VBYthhT2ZEIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5jqJX4uDXqC0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###To run this cell, your API key needs to be stored in the Colab Secret named as GOOGLE_API_KEY\n",
        "###To get the key, go to ai.google.dev"
      ],
      "metadata": {
        "id": "DxlBIz4EZFml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key= GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "K4c0v1wjmt_A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating embeddings\n",
        "\n",
        "To generate embeddings for a given data, use `embed_content` method and pass in which `model` to use and what `content` to convert:\n",
        "\n",
        "- `model`: Required. Must be either `models/text-embedding-004` or `models/embedding-001`.\n",
        "\n",
        "- `content`: Required. The data to embed.\n",
        "\n",
        "- `output_dimensionality`: Optional. Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. This is supported by `models/text-embedding-004`, but cannot be specified in `models/embedding-001`.\n",
        "\n",
        "- `task_type`: Optional. The task type for which the embeddings will be used.\n",
        "\n",
        "- `title`: Optional. You should only set this parameter if your task type is `retrieval_document` (or `document`)."
      ],
      "metadata": {
        "id": "UJpn4j5haZP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'Hi there, this is Gemini tutorial!'\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")"
      ],
      "metadata": {
        "id": "kBeQbJ97afQM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embed_data['embedding']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_StkmlaahwI",
        "outputId": "5ab7976a-0f6e-4582-8234-589dcfa4f6f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###As the embeddings have a large dimentionality (length of 768 array), we will output the first 10 embedding values of the data variable"
      ],
      "metadata": {
        "id": "4L4dT4mWapeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_data['embedding'][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-4HwVEhajOC",
        "outputId": "5a3746a7-f24e-47f8-ef18-365654ed85fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.058438968, 0.00044316906, -0.009973634, -0.016529616, 0.041487474, -0.013944049, 0.080064304, 0.055516902, -0.03406745, 0.046189807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Embedding a batch of data (list of strings)\n",
        "\n",
        "####This allows us to use a single API call more efficiently instead of calling it multiple times\n",
        "\n"
      ],
      "metadata": {
        "id": "VQHOs5zDa6w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    'What is the tuition at UC Berkeley?',\n",
        "    'Name top 10 books about machine learning.',\n",
        "    'How to stop procrastinating?'\n",
        "]\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")\n",
        "\n",
        "for embedding in embed_data['embedding']:\n",
        "    print(embedding[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Fan18XQza5Ul",
        "outputId": "d3e90924-06d5-44b2-c75e-a07bd6ac7e29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05558104, 0.066228844, -0.0832767, -0.0021693057, 0.027031252, 0.0060264543, 0.027830552, -0.017377941, -0.05279287, 0.035122644]\n",
            "[0.017529475, -0.026426788, 0.0011475749, -0.022670645, -0.03672292, 0.009089399, -0.021839937, 0.022415882, -0.021802153, -0.027643519]\n",
            "[0.003983932, -0.026754132, 0.061292212, -0.013258428, -0.02447549, 0.04371135, -0.00851315, 0.012199542, 0.02470629, -0.012365352]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Truncating embeddings\n",
        "###To reduce the dimentionality, we can specify the `output_dimentionality` argument"
      ],
      "metadata": {
        "id": "CjdPor_QbRMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content='Below is how you truncate data!',\n",
        "    output_dimensionality=10\n",
        ")\n",
        "\n",
        "print(len(embed_data['embedding']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cExiD6PsbC5C",
        "outputId": "0e5b0ad5-b1b7-439b-87d8-a085b2c3440b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specifying embeddings\n",
        "\n",
        "Since there are many different tasks where embeddings are used, you can refine them specifying for which one of the following `task_type`'s you are using embeddings for:\n",
        "\n",
        "- `unspecified`: If you do not set the value, it will default to `retrieval_query`.\n",
        "\n",
        "- `retrieval_query` (or `query`): The given text is a query in a search/retrieval setting.\n",
        "\n",
        "- `retrieval_document` (or `document`): The given text is a document from a corpus being searched. Optionally, also set the `title` parameter with the title of the document.\n",
        "\n",
        "- `semantic_similarity` (or `similarity`): The given text will be used for  Semantic Textual Similarity (STS).\n",
        "\n",
        "- `classification`: The given text will be classified.\n",
        "\n",
        "- `clustering`: The embeddings will be used for clustering.\n",
        "\n",
        "- `question_answering`: The given text will be used for question answering.\n",
        "\n",
        "- `fact_verification`: The given text will be used for fact verification."
      ],
      "metadata": {
        "id": "K9DuhX1ubgsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Depending on the `task_type`, the embeddings differ"
      ],
      "metadata": {
        "id": "Uo1g0KWxbo5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'Finally touching the grass!'\n",
        "\n",
        "embed_data_1 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        "    # no `task_type` specification; defaults to `retrieval_query`\n",
        ")\n",
        "\n",
        "embed_data_2 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data,\n",
        "    task_type='retrieval_document'\n",
        ")\n",
        "\n",
        "print(embed_data_1['embedding'][:10]) #printing the first 10 values\n",
        "print(embed_data_2['embedding'][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "2DxQdQG_beYs",
        "outputId": "db3d84cb-c095-48e6-c926-57827caaafc5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.044086624, -0.017505981, -0.014579227, 0.013675352, -0.008016501, 0.025225215, -0.035069168, 0.034015447, 0.037304174, 0.007439849]\n",
            "[-0.023972979, -0.019189887, -0.0222573, -0.012185102, 0.019129641, 0.035173632, -0.012367243, 0.016283926, 0.022629406, 0.014976865]\n"
          ]
        }
      ]
    }
  ]
}