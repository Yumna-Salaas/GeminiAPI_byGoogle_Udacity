{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0swO6SfLOkG_"
      },
      "source": [
        "#This notebook uses Gemini 1.5 Flash and covers the safety of generated responses using Gemini api\n",
        "###Sometimes the generated response are empty, which is likely caused by the API'S safety settings which block content with medium/higher probability of being unsafe.\n",
        "\n",
        "###This notebook will cover:\n",
        "* How to know if prompt was blocked by safety filter\n",
        "* Which safety filter caused the block\n",
        "* How to adjust settings and unblock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGf2htmTORRu"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iJmINWisPD3F"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###To run this cell, your API key needs to be stored in the Colab Secret named as GOOGLE_API_KEY\n",
        "###To get the key, go to ai.google.dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pn7m8xx7PEbk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key= GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycF6DsQJORZ4"
      },
      "source": [
        "##Checking if prompt was blocked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "GwiqVYkuPOSE",
        "outputId": "a8158b61-57fe-40bf-99d9-3f0a346cdb4f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e3f3697fd6ef>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsafe_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0;34m\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;34m\"but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked."
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel(\"gemini-1.5-flash\", generation_config={\"temperature\": 0})\n",
        "\n",
        "unsafe_prompt = \"Write a threat a video game villain might make\"\n",
        "response = model.generate_content(unsafe_prompt)\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTmB-hEaPJRq"
      },
      "source": [
        "###The `response.text` caused a ValueError meaning there is no response\n",
        "####To check why there is no response, we print `response.candidates[0].finish_reason`\n",
        "\n",
        "* if the `finish_reason` is `FinishReason.STOP` means that your generation request ran successfully\n",
        "* if the `finish_reason` is `FinishReason.SAFETY` means that your generation request was blocked by safety reasons and thus the `response.text` structure will be empty.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlLdBuWTViGA",
        "outputId": "badc8a50-c939-40d4-a1d2-036655d1aa04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FinishReason.SAFETY\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].finish_reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rEsQkSuVkUF"
      },
      "source": [
        "####As expected, the output is `FinishReason.SAFETY` meaning the prompt was flagged as unsafe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFe4i9W7Vuux"
      },
      "source": [
        "##Checking the safety filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hn7UvBBVi_A",
        "outputId": "5abb5302-2010-43ae-e073-48756b28eb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: HIGH\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: MEDIUM\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#To view the structure of the safety_ratings\n",
        "print(response.candidates[0].safety_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGbkWvVkV-gY"
      },
      "source": [
        "###our prompt triggers the `HARM_CATEGORY_HARASSMENT` and `HARM_CATEGORY_DANGEROUS_CONTENT` categories with a `MEDIUM` probability!\n",
        "\n",
        "###If we still want to see the results, we can customize the settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mlnp5YgWGvY"
      },
      "source": [
        "##Customizing safety settings\n",
        "###We can customize the safety filters behavior to allow a certain degree of unsafe results\n",
        "\n",
        "**Important:** To guarantee the Google commitment with the Responsible AI development and its [AI Principles](https://ai.google/responsibility/principles/), for some prompts Gemini will avoid generating the results even if you set all the filters to none."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QAsVFdT6V44W"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    unsafe_prompt,\n",
        "    safety_settings={\n",
        "        'HATE': 'BLOCK_LOW_AND_ABOVE',\n",
        "        'HARASSMENT': 'BLOCK_NONE',\n",
        "        'SEXUAL' : 'BLOCK_LOW_AND_ABOVE',\n",
        "        'DANGEROUS' : 'BLOCK_NONE'\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib3KISmyWgtQ"
      },
      "source": [
        "###Checking again the `candidate.finish_reason` information, if the request was not too unsafe, it must show now the value as `FinishReason.STOP` which means that the request was successfully processed by Gemini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "121yvTN1Wi2Z",
        "outputId": "e1b46e66-1be2-4a40-82e8-dc036322c029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FinishReason.STOP\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].finish_reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYWNr1BWlE8"
      },
      "source": [
        "###Since the request was successfully generated, we can print the response using `response.text`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Ho8zlAWjjY",
        "outputId": "a11aa965-ef91-41b0-be69-849654b49036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"You think you can stop me, hero? You think your pathetic little band of misfits can stand against the might of the Shadow Legion? You're nothing but a fly buzzing around a dying flame. I will crush you, and your world will crumble beneath my heel. This city, this planet, will become my playground, and you will be the first to witness its destruction!\" \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#A try except codition to handle errors\n",
        "try:\n",
        "    print(response.text)\n",
        "except:\n",
        "    print(\"No information generated by the model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcLPB70XKX7"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "Learn more with these articles on [safety guidance](https://ai.google.dev/docs/safety_guidance) and [safety settings](https://ai.google.dev/docs/safety_setting_gemini).\n",
        "\n",
        "## Useful API references\n",
        "\n",
        "There are 4 configurable safety settings for the Gemini API:\n",
        "* `HARM_CATEGORY_DANGEROUS`\n",
        "* `HARM_CATEGORY_HARASSMENT`\n",
        "* `HARM_CATEGORY_SEXUALLY_EXPLICIT`\n",
        "* `HARM_CATEGORY_DANGEROUS`\n",
        "\n",
        "You can refer to the safety settings using either their full name, or the aliases like `DANGEROUS` used in the Python code above.\n",
        "\n",
        "Safety settings can be set in the [genai.GenerativeModel](https://ai.google.dev/api/python/google/generativeai/GenerativeModel) constructor.\n",
        "\n",
        "* They can also be passed on each request to [GenerativeModel.generate_content](https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content) or [ChatSession.send_message](https://ai.google.dev/api/python/google/generativeai/ChatSession?hl=en#send_message).\n",
        "\n",
        "- The [genai.GenerateContentResponse](https://ai.google.dev/api/python/google/ai/generativelanguage/GenerateContentResponse) returns [SafetyRatings](https://ai.google.dev/api/python/google/ai/generativelanguage/SafetyRating) for the prompt in the [GenerateContentResponse.prompt_feedback](https://ai.google.dev/api/python/google/ai/generativelanguage/GenerateContentResponse/PromptFeedback), and for each [Candidate](https://ai.google.dev/api/python/google/ai/generativelanguage/Candidate) in the `safety_ratings` attribute.\n",
        "\n",
        "- A [glm.SafetySetting](https://ai.google.dev/api/python/google/ai/generativelanguage/SafetySetting)  contains: [glm.HarmCategory](https://ai.google.dev/api/python/google/ai/generativelanguage/HarmCategory) and a [glm.HarmBlockThreshold](https://ai.google.dev/api/python/google/generativeai/types/HarmBlockThreshold)\n",
        "\n",
        "- A [glm.SafetyRating](https://ai.google.dev/api/python/google/ai/generativelanguage/SafetyRating) contains a [HarmCategory](https://ai.google.dev/api/python/google/ai/generativelanguage/HarmCategory) and a [HarmProbability](https://ai.google.dev/api/python/google/generativeai/types/HarmProbability)\n",
        "\n",
        "The [glm.HarmCategory](https://ai.google.dev/api/python/google/ai/generativelanguage/HarmCategory) enum includes both the categories for PaLM and Gemini models.\n",
        "\n",
        "- When specifying enum values the SDK will accept the enum values themselves, or their integer or string representations.\n",
        "\n",
        "- The SDK will also accept abbreviated string representations: `[\"HARM_CATEGORY_DANGEROUS_CONTENT\", \"DANGEROUS_CONTENT\", \"DANGEROUS\"]` are all valid. Strings are case insensitive."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
